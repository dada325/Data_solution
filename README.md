# Data Solution Code
Find question to practise with.
Find practical solutions to your coding problems in data science.


## About this Page




### What will I build in this page?





## Description
When I first confront a problem of data science, I want to try to solve it with the knowledge from the book. But most of time it fails, the problem may be too complex and not easy to abstract to a computer problem. 

We understand the challenges and complexities that data scientists face while working on various projects. Our mission is to provide a comprehensive platform where data science enthusiasts and professionals can find practical solutions to their coding problems.

We want to cover a wide range of topics, including data preprocessing, data visualization, machine learning algorithms, statistical analysis, deep learning, natural language processing, Reinforcement learning and more. We believe in hands-on learning, so you'll find plenty of interactive coding exercises and projects that allow you to apply your newfound knowledge. Now the Contents is still Work in progress.

## Status:
 now WIP is the section of Reinforcement learning, so please feel free to fork of other section. 

## Machine Learning 

- Supervised Learning

- Unsupervised Learning

- Deep Learning

- Natural Language Processing (NLP)

- Computer Vision

- Recommender Systems

- Time Series Forecasting

- Transfer Learning

- Adversarial Machine Learning

- AutoML (Automated Machine Learning)

- Reinforcement Learning.


 0. The Basic

 ####Some of the library
 1. [OpenAI Baselines](https://github.com/openai/baselines)
2. [Stable Baselines](https://github.com/DLR-RM/stable-baselines3)
3. [TF Agents](https://github.com/tensorflow/agents)
4. [Keras-RL](https://github.com/keras-rl/keras-rl)
5. [Keras-RL2](https://github.com/wau/keras-rl2)
6. [PyQlearning](https://github.com/chimera0/accel-brain-code/tree/master/Reinforcement-Learning)
7. [Tensorforce](https://github.com/tensorforce/tensorforce)
8. [RL Coach](https://github.com/NervanaSystems/coach)
9. [Chainer RL](https://github.com/chainer/chainerrl)
10. [Mushroom RL](https://github.com/MushroomRL/mushroom-rl)
11. [Acme](https://github.com/deepmind/acme)
12. [Dopamine](https://github.com/google/dopamine)
13. [RLLib](https://github.com/ray-project/ray)
14. [TRFL](https://github.com/deepmind/trfl)
15. [ReAgent](https://github.com/facebookresearch/ReAgent)
16. [MAgent](https://github.com/PettingZoo-Team/MAgent)
17. [SLM Lab](https://github.com/kengz/SLM-Lab)
18. [DeeR](https://github.com/VinF/deer)
19. [Spinning Up](https://github.com/openai/spinningup)
20. [Surreal](https://github.com/SurrealAI/surreal)

 1. The Intersection of Reinforcement Learning and other discipline
      * Economics
      * Psychology
      * Neuroscience
      * Computer Science
      * Engineering
      * Mathematic
 
 2. Some of the Paper reviews


| Algorithm                                       | Authors           | Year |
|-------------------------------------------------|-------------------|------|
| [A2C / A3C (Asynchronous Advantage Actor-Critic)](https://arxiv.org/abs/1602.01783) | Mnih et al        | 2016 |
| [PPO (Proximal Policy Optimization)](https://arxiv.org/abs/1707.06347)              | Schulman et al    | 2017 |
| [TRPO (Trust Region Policy Optimization)](https://arxiv.org/abs/1502.05477)         | Schulman et al    | 2015 |
| [DDPG (Deep Deterministic Policy Gradient)](https://arxiv.org/abs/1509.02971)       | Lillicrap et al   | 2015 |
| [TD3 (Twin Delayed DDPG)](https://arxiv.org/abs/1802.09477)                         | Fujimoto et al    | 2018 |
| [SAC (Soft Actor-Critic)](https://arxiv.org/abs/1801.01290)                         | Haarnoja et al    | 2018 |
| [DQN (Deep Q-Networks)](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)                           | Mnih et al        | 2013 |
| [C51 (Categorical 51-Atom DQN)](https://arxiv.org/abs/1707.06887)                   | Bellemare et al   | 2017 |
| [QR-DQN (Quantile Regression DQN)](https://arxiv.org/abs/1710.10044)               | Dabney et al      | 2017 |
| [HER (Hindsight Experience Replay)](https://arxiv.org/abs/1707.01495)               | Andrychowicz et al| 2017 |
| [World Models](https://worldmodels.github.io/)                                  | Ha and Schmidhuber| 2018 |
| [I2A (Imagination-Augmented Agents)](https://arxiv.org/abs/1707.06203)              | Weber et al       | 2017 |
| [MBMF (Model-Based RL with Model-Free Fine-Tuning)](https://sites.google.com/view/mbmf)| Nagabandi et al  | 2017 |
| [MBVE (Model-Based Value Expansion)](https://arxiv.org/abs/1803.00101)              | Feinberg et al    | 2018 |
| [AlphaZero](https://arxiv.org/abs/1712.01815)                                      | Silver et al      | 2017 |
| [A Path Towards Autonomous Machine Intelligence](https://openreview.net/pdf?id=BZ5a1r-kVsf)|LeCun et al| 2022 | 
| [DreamerV3](https://arxiv.org/pdf/2301.04104.pdf)                                  | Hafner et al      | 2023|

  3. Model & Algorithm
      * DP
      * Monte Carlo Methods
      * TD
      * DQN
      * REINFORCE
      * PPO
      * DDPG
      * Finance
      * Control
      * Discretization
  4. Task
      * Navigation
      * Continous Control
      * 
  5. Case Study






## Main task

- Mathmatic
- Data Processing
- Machine Learning 
- Deep Learning
- Reinforcement Learning


## Reading



## Contributing

Guidelines for contributing to the project, including instructions for setting up a development environment and submitting pull requests.

## License

Information about the project's license and any relevant disclaimers.
